---
title: "timeOmics"
author: 
- name:  "Antoine Bodein"
  affiliation: "CHU de Québec Research Center, Université Laval, Molecular Medicine department, Québec, QC, Canada"
  email: "antoine.bodein.1@ulaval.ca"
package: timeOmics
output: 
  BiocStyle::html_document
vignette: >
  %\VignetteIndexEntry{timeOmics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}  
---

# Introduction

***timeOmics*** is a generic data-driven framework to integrate multi-Omics longitudinal data (**A.**) measured on the same biological samples and select key temporal features with strong associations within the same sample group.

The main steps of ***timeOmics*** are:

* a pre-procesing step (**B.**) to normalize and filter low-expressed and not time-varying features,
* a modelling step (**C.**) to capture inter-individual variability in biological/technical replicates.
* a clustering step (**D.**) to group features with the same expression profile over time. We can also use a feature selection step to identify a signature per cluster.
* a post-hoc validation step (**E.**) to ensure clustering quality.

We present this framework on both single-Omic and multi-Omics situations.

![Framework Overview](./img/method_overview.png)

For more details please check:  
*Bodein A, Chapleur O, Droit A and Lê Cao K-A (2019) A Generic Multivariate Framework for the Integration of Microbiome Longitudinal Studies With Other Data Types. Front. Genet. 10:963. doi: 10.3389/fgene.2019.00963*

# Start

## Installation

```{r, echo =  FALSE}
knitr::opts_chunk$set(eval = TRUE, 
                      echo = TRUE,
                      fig.align = "center",
                      warning = FALSE,
                      message = FALSE)
```


```r
install.packages("devtools")
# then load
library(devtools)
install_github("abodein/timeOmics_BioC")
```

## Load the package

```{r, message=FALSE, warning=FALSE}
library(timeOmics)
```

## Required data

Each omics technology produces abundance tables with samples in rows and features in columns (genes, proteins, species, ...).
In multi-Omics, each *block* has the same rows and a variable number of columns depending on the technology and number of identified features.

We assume each block is a matrix/data.frame with samples in rows (similar in each block) and features in columns (variable number of column).

For this example, we will use simulated data based on the above-mentioned article.

```{r}
data("timeOmics.simdata")
raw.data <- timeOmics.simdata$rawdata

dim(sim.data) 
head(raw.data[1:6])
```


# Data preprocessing

Every analysis starts with a pre-processing step. 
In longitudinal multi-omics analysis we have a 2-step pre-processing procedure.

## Omic-specific

Omic-specific pre-processing is the type of standardization normally used without time component.
It may differ depending on the type of technology
*(log, scale, rle, low count removal, ...)*.
That is why we let the user apply his favorite method of standardization.

## Time-specific

In a longitudinal context, one can be interested only in features that vary over time and filter out molecules that would have a negligible impact on the system.

To do so, we can first naively set a threshold on the variation coefficient and keep those features that exceed the threshold.

```{r}
remove.low.cv <- function(X, cutoff = 0.5){
  # var.coef
  cv <- unlist(lapply(as.data.frame(X), 
                      function(x) abs(sd(x)/mean(x))))
  return(X[,cv > cutoff])
}

data.filtered <- remove.low.cv(sim.data, 0.5)
```


# Time Modelling

We rely on a *Linear Mixed Model Splines* framework (package `lmms`) to model features expression as a function of time by taking into account all inter-individual variability.

`lmms` framework tests 4 different models and assigns one of the following models to each feature:

* 0 = linear model, 
* 1 = linear mixed effect model spline (LMMS) with defined basis, 
* 2 = LMMS taking subject-specific random intercept, 
* 3 = LMMS with subject specific intercept and slope.

The package also has an interesting feature for filtering profiles not differentially expressed over time, in a more robust way (see `lmms::lmmsDE`).

At the end, `lmms` summarize each feature into a unique time profile.

## Required data

Let's run `lmms` on simulated dataset.


```{r}
library(lmms)
library(tidyverse) # this one will be useful for the rest

```

LMMS requires a dataframe with features in columns and samples in rows.
Here my rownames are represented like this: **ID_Time**

For more information about LMMS modelling parameters, please check (link lmms)

```{r}
time <- rownames(sim.data) %>% str_remove("._") %>% as.numeric()
LMMS.output <- lmms::lmmSpline(data = sim.data, time = time,
                        sampleID = rownames(sim.data), deri = FALSE,
                        basis = "p-spline", numCores = 4, timePredict = 1:9, 
                        keepModels = TRUE)
data <- t(LMMS.output@predSpline)
```

## LMMS output 

LMMS reduces the dimension of the data.
The produced table contains features in columns and now, times in lines.

Let's plot the modelled profiles.

```{r}
# gather data
data.gathered <- data %>% as.data.frame() %>% 
  rownames_to_column("time") %>%
  mutate(time = as.numeric(time)) %>%
  gather(feature, value, -time)

# plot profiles
ggplot(data.gathered, aes(x = time, y = value, color = feature)) + geom_line() +
  theme_bw() + ggtitle("LMMS profiles") + ylab("Features expression") +
  xlab("Time")
```

## Profile filtering

Straight line modelling can occur when the inter-individual variation is too high.
To remove the noisy profiles, we first use the Breusch-Pagan test, which tests the homo-sedasticity of the residues.
We then add a filter on the mean squared error to reduce the dispersion of the residues around the line.

```{r}
#wrapper.filter.splines
```

# Single-Omic longitudinal clustering

## (s)PCA 

From the modelled data, we use a PCA to cluster features with a samilar expression profile over time.

PCA is un unsupervised reduction dimension technique which use uncorrelated 
intrumental variable (a.k.a principal components) to summarize as much information 
(*variance*) as possible from the data.

```{r}
data("timeOmics.simdata")
data <- timeOmics.simdata$modelled
```

## clustering

Text about clustering and how it is done in our case. 

* loading scores
* component
* contribution
* silhouette coefficient

Optimize the number of component
First, run a PCA and optimise 

```{r}
# run pca
pca.res <- pca(X = data, ncomp = 5, scale=F)

pca.ncomp <- getNcomp(pca.res, max.ncomp = 5, X = data)
plot(pca.ncomp)
```

Thanks to the previous plot, highest silhouette coefficient is achieved when `ncomp = 2`.

```{r}
pca.res <- pca(X = data, ncomp = 2,scale = F, center=F)
```

All information about the cluster is displayed here.

```{r}
# extract cluster
pca.cluster <- getCluster(pca.res)
head(pca.cluster)
```

### Plot PCA clusters

```{r}
plotVar(pca.res)
plotLong(pca.res, scale = F, center = F)
```


## sparse PCA

The previous clustering used all features. Sometimes we are interested in a cluster signature.
We then use the sparse PCA to extract this key signature.

To find the right number of features to keep per component and thus per cluster, we evaluate the silhouette for a list of selected features on each component.

We do not recommend using a parameter that is too small since it will tend to pull the silhouette coefficient upwards and bias the interpretation regarding the number of features to be selected.

We will then follow the evolution of the silhouette coefficient of each cluster (component and contribution). 
The main idea here is to detect a significant decrease in the evolution of the silhouette for each component.
In other words, if we add 1 OTU, will the cluster be distorted?

```{r}
data <- timeOmics.simdata$modelled
tune.spca.res <- tuneCluster.spca(X = data, ncomp = 2, test.keepX = c(2:10))
plot(tune.spca.res)
```



```{r}
spca.res <- spca(X = data, ncomp = 2, keepX = c(8,7), scale = FALSE)
plotLong(spca.res)
```


# (s)PLS longitudinal clustering

```{r}
X <- data
Y <- data[,sample(1:20, size = 8)]
colnames(Y) <- paste0("Y", 1:ncol(Y))

pls.res <- pls(X,Y, ncomp = 2, scale = TRUE)

getCluster(pls.res) %>% head

plotLong(pls.res)

tune.spls <- tuneCluster.spls(X, Y, ncomp = 2, test.keepX = c(5,10,15,20), test.keepY <- c(2,4,6))
```

need a graph for keepX/keepY

# Multi-block (s)PLS longitudinal clustering

```{r}
X <- data
Y <- data[,sample(1:20, size = 8)]
colnames(Y) <- paste0("Y", 1:ncol(Y))

Z <- data[,sample(1:20, size = 12)]
colnames(Z) <- paste0("Z", 1:ncol(Z))

block.pls.res <- block.pls(X = list("X"=X,"Z"=Z), Y, ncomp = 2, scale = TRUE)

block.pls.cluster <- getCluster(block.pls.res)
head(block.pls.cluster)

plotLong(block.pls.res)
```


# Post-hoc evaluation

We compute the proportionality distance between features of the same cluster.
By keeping the features close to each other, it guarantees the authenticity of the interactions.
We also use a Wilcoxon U-test to compare the within cluster median compared to the entire background set.


```{r, eval =T}
# example fro multiblock analysis
res <- timeOmics::proportionality(block.pls.res)
# distance between pairs of features
head(res$propr.distance)[1:6]
# u-test pvalue by clusters
pval.propr <- res$pvalue 
knitr::kable(pval.propr)
plot(res)
```
